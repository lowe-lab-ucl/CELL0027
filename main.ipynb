{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL0027 \n",
    "## Introduction to Machine Learning for bioimage analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the repo so we have a local copy\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !git clone -q https://github.com/lowe-lab-ucl/CELL0027.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading all of the prerequisite Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np \n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.util import montage\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = Path(\"./CELL0027/data/data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data.keys():\n",
    "    m = montage(data[key], grid_shape=(2, 25))\n",
    "    fig, ax = plt.subplots(figsize=(16, 2))\n",
    "    ax.imshow(m)\n",
    "    ax.axis(False)\n",
    "    ax.set_title(key.title())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate the intensity histograms for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data[\"interphase\"][0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Determine the threshold value for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a function to segment the images based on a threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image: npt.NDArray, threshold: float) -> npt.NDArray:\n",
    "    # implement your segmentation function here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = segment(data[\"interphase\"][0], threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write code to perform edge detection using the pytorch convolutional kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initialising a 2D convolutional operator using `pytorch`:\n",
    "\n",
    "$$\n",
    "\\text{out}(N_i,C_{out_j}) = \\text{bias}(C_{out_j}) + \\sum_{k=0}^{C_{in}-1} \\text{weight}(C_{out_j},k)~\\star~\\text{input}(N_i,k)\n",
    "$$\n",
    "\n",
    "Where the input size is $(N,C_{in},H,W)$ and the output size is $(N,C_{out},H,W)$. The dimensions of the image are $(H,W)$, which is $(80,80)$ for this dataset. $N$ is the batch size, or number of images analysed simultaneously. The $\\star$ operator is the valid 2D cross-correlation operator. Since we only have one channel for our input data, and we only want to calculate the convolution with a single filter $C_{in} = C_{out} = 1$.\n",
    "\n",
    "You can read the documentation for the 2D convolutional operator here:\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_in = 1 \n",
    "C_out = 1\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "conv = torch.nn.Conv2d(\n",
    "    C_in, \n",
    "    C_out, \n",
    "    kernel_size,\n",
    "    bias=False,\n",
    "    padding=\"same\",\n",
    ")\n",
    "conv.requires_grad_ = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the weights before we set anything. Notice that they're random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can define a kernel for the convolution operator. Given the parameters above, the kernel needs to be of size $(C_{in}, C_{out}, H, W)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = np.array([\n",
    "    # specify the kernel here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the weights are the correct size\n",
    "assert sobel_x.shape == conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to manually set the weights of the convolutional operator here\n",
    "with torch.no_grad():\n",
    "    print(conv.weight.shape)\n",
    "    conv.weight = torch.nn.Parameter(torch.from_numpy(sobel_x).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take some example data and apply the convolution operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (data[\"metaphase\"].astype(np.float32)[:, None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_out = conv(torch.from_numpy(x)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "ax[0].imshow(\n",
    "    montage(np.squeeze(x), grid_shape=(5, 10), rescale_intensity=True)\n",
    ")\n",
    "ax[0].axis(False)\n",
    "ax[0].set_title(\"Raw image data\")\n",
    "ax[1].imshow(\n",
    "    montage(np.squeeze(x_out), grid_shape=(5, 10), rescale_intensity=True),\n",
    ")\n",
    "ax[1].axis(False)\n",
    "ax[1].set_title(\"Convolution with Sobel kernel, $G_x$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a nework to perform edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to learn the sobel kernel using machine learning. We have an input image, and the ground truth transformed image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.from_numpy(x_out)\n",
    "x_in = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a loss function that let's us measure the error between our models output and the expected value. We'll use the Mean Squared Error (MSE) loss for now since we're performing a regression task.\n",
    "\n",
    "You can learn about the standard loss functions here:\n",
    "https://pytorch.org/docs/stable/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define a model. Here's a simple one that just performs the convolution operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SobelModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            C_in,\n",
    "            C_out,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SobelModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the model definition here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up an optimiser that will do the gradient descent to perform the optimisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the pytorch training loop that updates the model based on the calculated loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_iterations = 10_000\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "\n",
    "# we perform n training iterations, updating the weights after every iteration\n",
    "# the model should converge on a solution\n",
    "for i in tqdm(range(n_training_iterations), desc=\"Training model\"):\n",
    "    # zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # make predictions for this batch\n",
    "    y_hat = model(x_in)\n",
    "\n",
    "    # compute the loss and its gradients\n",
    "    loss = loss_fn(y_hat, y_true)\n",
    "    loss.backward()\n",
    "\n",
    "    # adjust learning weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # store the loss\n",
    "    loss_history.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the learned kernel, how does it compare to what we expect?\n",
    "model.conv.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
